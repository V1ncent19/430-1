\documentclass[11pt,a4paper]{article}
%以下为所使用的宏包
\usepackage{ulem}%下划线
\usepackage{amsmath,amsfonts,amssymb,amsthm,amsbsy}%数学符号
\usepackage{graphicx}%插入图片
\usepackage{booktabs}%三线表
%\usepackage{indentfirst}%首行缩进
\usepackage{tikz}%作图
\usepackage{appendix}%附录
\usepackage{array}%多行公式/数组
\usepackage{makecell}%表格缩并
\usepackage{siunitx}%SI单位--\SI{number}{unit}
\usepackage{mathrsfs}%数学字体
\usepackage{enumitem}%列表间距
\usepackage{multirow}%列表横向合并单元格
\usepackage[colorlinks,linkcolor=red,anchorcolor=blue,citecolor=green]{hyperref}%超链接引用
\usepackage{float}%图片、表格位置排版
\usepackage{pict2e,keyval,fp,diagbox}%带有斜线的表格
\usepackage{fancyvrb,listings}%设置代码插入环境
\usepackage{minted}%代码环境设置
\usepackage{fontspec}%字体设置
\usepackage{color,xcolor}%颜色设置
\usepackage{titlesec} %自定义标题格式
\usepackage{tabularx}%列表扩展
\usepackage{authblk}%titlepage作者信息
\usepackage{nicematrix}%更好的矩阵标定
\usepackage{fbox}%更多浮动体盒子



%以下是页边距设置
\usepackage[left=0.5in,right=0.5in,top=0.81in,bottom=0.8in]{geometry}

%以下是段行设置
\linespread{1.4}%行距
\setlength{\parskip}{0.1\baselineskip}%段距
\setlength{\parindent}{2em}%缩进


%其他设置
\numberwithin{equation}{section}%公式按照章节编号
\newenvironment{point}{\raggedright$\blacktriangleright$}{}
\newenvironment{algorithm}[1]{\vspace{12pt} \hrule\hrule \vspace{3pt} \noindent\textbf{\color[HTML]{E63F00}Algorithm } \,\textit{#1} \vspace{3pt} \hrule\vspace{6pt}}{\vspace{6pt}\hrule\hrule \vspace{12pt}} % 算法伪代码格式环境


%代码环境\lst设置
\definecolor{CodeBlue}{HTML}{268BD2}
\definecolor{CodeBlue2}{HTML}{0000CD}
\definecolor{CodeGreen}{HTML}{2AA1A2}
\definecolor{CodeRed}{HTML}{CB4B16}
\definecolor{CodeYellow}{HTML}{B58900}
\definecolor{CodePurPle}{HTML}{D33682}
\definecolor{CodeGreen2}{HTML}{859900}
\lstset{
    basicstyle=\tt,%字体设置
    numbers=left, %设置行号位置
    numberstyle=\tiny\color{black}, %设置行号大小
    keywordstyle=\color{black}, %设置关键字颜色
    stringstyle=\color{CodeRed}, %设置字符串颜色
    commentstyle=\color{CodeGreen}, %设置注释颜色
    frame=single, %设置边框格式
    escapeinside=`, %逃逸字符(1左面的键)，用于显示中文
    %breaklines, %自动折行
    extendedchars=false, %解决代码跨页时，章节标题，页眉等汉字不显示的问题
    xleftmargin=2em,xrightmargin=2em, aboveskip=1em, %设置边距
    tabsize=4, %设置tab空格数
    showspaces=false, %不显示空格
    emph={TRUE,FALSE,NULL,NAN,NA,<-,},emphstyle=\color{CodeBlue2}, %其他高亮}
}


%节标题格式设置
\titleformat{\section}[block]{\large\bfseries}{Exercise \arabic{section}}{1em}{}[]
\titleformat{\subsection}[block]{}{    \arabic{section}.(\alph{subsection})}{1em}{}[]
% \titleformat{\subsubsection}[block]{\normalsize\bfseries}{    \arabic{subsection}-\alph{subsubsection}}{1em}{}[]
% \titleformat{\paragraph}[block]{\small\bfseries}{[\arabic{paragraph}]}{1em}{}[]


% \titleformat{\sectioncommand}[shape]{format}{title-label}{sep}{before-title}[after-title]



% 中文字号
% 初号42pt, 小初36pt, 一号26pt, 小一24pt, 二号22pt, 小二18pt, 三号16pt, 小三15pt, 四号14pt, 小四12pt, 五号10.5pt, 小五9pt



\begin{document}

\begin{center}\thispagestyle{plain}

{\LARGE\textbf{STAT 430-1, Fall 2024}}

{\Large\textbf{HW3}}

Tuorui Peng\footnote{TuoruiPeng2028@u.northwestern.edu}
\end{center}

\thispagestyle{myheadings}\markright{Compiled using \LaTeX}
\pagestyle{myheadings}\markright{Tuorui Peng}

% show only sections level in contents
\setcounter{tocdepth}{1}
\tableofcontents

  

\section{Convolution}

\textbf{Notation:} I use $ \fallingdotseq $ for Fourier transform and $ \risingdotseq $ for inverse Fourier transform. i.e. $ f(x)\fallingdotseq \phi (t) $ and $ \phi (t)\risingdotseq f(x) $.

We utilize the relation between convolution and Fourier transform to solve the convolution problem. For the given distributions $ f(x) $ we have their characteristic functions $ \phi (t) $ as follows:
\begin{itemize}[topsep=2pt,itemsep=0pt]
    \item \textbf{Binomial:} 
    \begin{align*}
        f(x)=\binom{n}{x}p^x(1-p)^{n-x} \fallingdotseq (p+(1-p)e^{it})^n
    \end{align*}
    \item \textbf{Poisson:}
    \begin{align*}
        f(x)=\frac{\lambda^x}{x!}e^{-\lambda} \fallingdotseq e^{\lambda(e^{it}-1)} 
    \end{align*}
    \item \textbf{Geometric:}
    \begin{align*}
        f(x)=p(1-p)^x \fallingdotseq \frac{p}{1-(1-p)e^{it}} 
    \end{align*}
    \item \textbf{Normal:}
    \begin{align*}
        f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \fallingdotseq e^{it\mu-\frac{1}{2}\sigma^2t^2} 
    \end{align*}
    \item \textbf{Exponential:}
    \begin{align*}
        f(x)=\lambda e^{-\lambda x} \fallingdotseq \frac{\lambda}{\lambda-it} 
    \end{align*}
\end{itemize}

Using the transformation that
\begin{align*}
    f_{X+Y}(\xi )\fallingdotseq \phi_X(t )\cdot \phi_Y(t ) 
\end{align*}
we have the following for summation of two distributions:

\begin{itemize}[topsep=2pt,itemsep=0pt]
    \item \textbf{Binomial:} 
    \begin{align*}
        X\sim \mathrm{ Binom }(n,p)\fallingdotseq (p+(1-p)e^{it})^n := \phi _X(t)\\
        Y\sim \mathrm{ Binom }(m,p)\fallingdotseq (p+(1-p)e^{it})^m := \phi _Y(t)\\
        \phi _X(t)\cdot \phi _Y(t)=(p+(1-p)e^{it})^{n+m}\risingdotseq \mathrm{ Binom }(n+m,p)
    \end{align*}
    \item \textbf{Poisson:}
    \begin{align*}
        X\sim \mathrm{ Poisson }(\lambda )\fallingdotseq e^{\lambda(e^{it}-1)} := \phi _X(t)\\
        Y\sim \mathrm{ Poisson }(\mu )\fallingdotseq e^{\mu(e^{it}-1)} := \phi _Y(t)\\
        \phi _X(t)\cdot \phi _Y(t)=e^{(\lambda+\mu)(e^{it}-1)}\risingdotseq \mathrm{ Poisson }(\lambda+\mu) 
    \end{align*}
    \item \textbf{Geometric:}
    \begin{align*}
        X\sim \mathrm{ Geometric }(p)\fallingdotseq \frac{p}{1-(1-p)e^{it}} := \phi _X(t)\\
        Y\sim \mathrm{ Geometric }(p)\fallingdotseq \frac{p}{1-(1-p)e^{it}} := \phi _Y(t)\\
        \phi _X(t)\cdot \phi _Y(t)=\left(\frac{p}{1-(1-p)e^{it}}\right)^2\risingdotseq \mathrm{ Negative\,Binom }(2,p)
    \end{align*}
    \item \textbf{Normal:}
    \begin{align*}
        X \sim \mathrm{ Normal }(m_1,\sigma _1^2 )\fallingdotseq e^{im_1t-\frac{1}{2}\sigma _1^2t^2} := \phi _X(t)\\
        Y \sim \mathrm{ Normal }(m_2,\sigma _2^2 )\fallingdotseq e^{im_2t-\frac{1}{2}\sigma _2^2t^2} := \phi _Y(t)\\
        \phi _X(t)\cdot \phi _Y(t)=e^{i(m_1+m_2)t-\frac{1}{2}(\sigma _1^2+\sigma _2^2)t^2}\risingdotseq \mathrm{ Normal }(m_1+m_2,\sigma _1^2+\sigma _2^2)
    \end{align*}
    \item \textbf{Exponential:}
    \begin{align*}
        X\sim \mathrm{ Exponential }(\lambda )\fallingdotseq \frac{\lambda}{\lambda-it} := \phi _X(t)\\
        Y\sim \mathrm{ Exponential }(\mu )\fallingdotseq \frac{\mu}{\mu-it} := \phi _Y(t)
    \end{align*}
    the summation is not any known distribution, we just give the CDF here:
    \begin{align*}
        \mathbb{P}\left( X+Y\leq t \right) =& \int_0^\infty \,\mathrm{d}x \int_0^{t-x} \,\mathrm{d}y\, \lambda e^{-\lambda x}\mu e^{-\mu y}\\
        =& 1-\dfrac{ \mu e^{-\lambda t} - \lambda e^{-\mu t}}{\mu -\lambda }.
    \end{align*}

    At $ \mu \to\lambda  $ limit we have
    \begin{align*}
        \mathbb{P}\left( X+Y\leq t \right) = 1-\lambda te^{-\lambda t}. 
    \end{align*}
    which is the CDF of Gamma distribution $ \Gamma (2,\lambda ) $.
    
\end{itemize}




\section{Cauchy-Schwarz Inequality}
\subsection{}
Consider the following:
\begin{align*}
    0\leq &\mathbb{E}\left[  \left( \left\vert X \right\vert  \mathbb{E}\left[ Y^2 \right] - \left\vert Y \right\vert \mathbb{E}\left[ \left\vert XY \right\vert  \right]    \right)^2  \right]  \\
    =& \mathbb{E}\left[ \left\vert X \right\vert ^2 \mathbb{E}\left[ Y^2 \right]^2 -2\left\vert XY \right\vert \mathbb{E}\left[ Y^2 \right] \mathbb{E}\left[ \left\vert XY \right\vert  \right] + \left\vert Y \right\vert ^2 \mathbb{E}\left[ \left\vert XY \right\vert  \right]^2   \right] \\
    =&\mathbb{E}\left[ Y^2 \right]\left\{  \mathbb{E}\left[ X^2 \right] \mathbb{E}\left[ Y^2 \right] -  \mathbb{E}\left[ \left\vert XY \right\vert   \right]^2    \right\} 
\end{align*}
thus we have
\begin{align*}
    \mathbb{E}\left[ \left\vert XY \right\vert  \right] \leq \sqrt{\mathbb{E}\left[ X^2 \right] \mathbb{E}\left[ Y^2 \right] }.
\end{align*}

\subsection{}

WLOG we assume $ X $ and $ Y $ are both mean-zero. Using Jensen's inequality we have
\begin{align*}
    \mathrm{ Cov }(X,Y)=& \mathbb{E}\left[ XY \right] \leq \left\vert \mathbb{E}\left[ XY \right]  \right\vert   \leq \mathbb{E}\left[ \left\vert XY \right\vert  \right] \leq \sqrt{\mathbb{E}\left[ X^2 \right] \mathbb{E}\left[ Y^2 \right] }= \sqrt{\mathrm{ Var }(X)\mathrm{ Var }(Y)}.
\end{align*}


\section{Chernoff Bound}

\subsection{}

Using the Markov inequality we have
\begin{align*}
    \mathbb{P}\left( X\geq m \right) = & \mathbb{P}\left( e^{tX}\geq e^{tm} \right) \leq \dfrac{ \mathbb{E}\left[ e^{tX} \right] }{e^{tm}}.
\end{align*}

\subsection{}

Using Jensen's inequality we have
\begin{align*}
    \mathbb{E}\left[ e^{tX} \right] =& \prod_{i=1}^n \mathbb{E}\left[ e^{tX_i} \right]\\
    =& \prod_{i=1}^n \left( 1-p_i+p_ie^t \right)\\  
    =&\exp\left[ n\cdot\dfrac{ 1 }{ n }\sum_{i=1}^n \log \left( 1-p_i+p_ie^t \right)  \right]\\
    \leq & \exp\left[ n\cdot \log \dfrac{ 1 }{ n }\sum_{i=1}^n \left( 1-p_i+p_ie^t \right)  \right]\\
    =& \exp\left[ n\cdot \log \left(e^tp+1-p\right)  \right]\\
    =& \left( e^tp+1-p \right)^n.
\end{align*}

\subsection{}

By Chernoff bound we have
\begin{align*}
    \mathbb{P}\left( X\geq \mu +\lambda  \right) \leq e^{-t(\mu +\lambda)}\left( e^tp+1-p \right)^n,\quad \forall t>0.
\end{align*}

Denote $ \xi := p+\dfrac{ \lambda  }{ n }  $, we optimize the bound by setting the minimizer $ t_0=\log \dfrac{ 1-p }{ p }\dfrac{ \xi  }{ 1-\xi  }   $, which gives
\begin{align*}
    \mathbb{P}\left( X\geq \mu +\lambda  \right) \leq& e^{-t_0(\mu +\lambda)}\left( e^{t_0}p+1-p \right)^n\\
    =&\exp\left[ -n (\xi \log\dfrac{ \xi  }{ p } + (1-\xi )\log\dfrac{ 1-\xi  }{ 1-p }  ) \right]\\
    =&\exp\left[ -n H_p(\xi ) \right]  =\exp\left[ -n H_p(p+\dfrac{ \lambda  }{ n }  ) \right]
\end{align*}



\subsection{}
It suffices to prove that $ H_p(p+\dfrac{ \lambda  }{ n } ) \geq 2\dfrac{ \lambda ^2 }{ n }  $. To illustrate this, we consider the function $ f(x)=H_p(x) - 2(x-p)^2  = x\log\dfrac{ x }{ p } +(1-x)\log\dfrac{ 1-x }{ 1-p } -2(x-p)^2  $, we have
\begin{align*}
    \dfrac{\mathrm{d}^{} f(x) }{\mathrm{d} x^{} }=& \log\dfrac{ x }{ p } -\log\dfrac{ 1-x }{ 1-p }  + 4p-4x\\
    \dfrac{\mathrm{d}^{2} f(x) }{\mathrm{d} x^{2} }=& \dfrac{ 1 }{ x } +\dfrac{ 1 }{ 1-x } -4 \geq 0. 
\end{align*}
Thus by further noticing that $ f'(x)<0 $ at $ [0,p] $ and $ f'(x)>0 $ at $ [p,1] $ and $ f(p)=0 $, we have $ f(x)\geq 0 $ for $ x\in [0,1] $, which implies $ H_p(x)\geq 2(x-p)^2 $ for $ x\in [0,1] $, thus we have
\begin{align*}
    \mathbb{P}\left( X\geq \mu +\lambda  \right) \leq&\exp\left[ -n H_p(p+\dfrac{ \lambda  }{ n }  ) \right] \leq \exp\left[ -\dfrac{ 2\lambda ^2 }{ n }  \right]
\end{align*}






\section{On the LLN}


\subsection{}

We have
\begin{align*}
    \mathbb{E}\left[ X_n \right] = n^2\cdot \dfrac{ 1 }{ n^2 } =1.  
\end{align*}


\subsection{}
Note that we have the following:
\begin{align*}
    \forall n\geq N,\, X_n = 0 \Rightarrow \lim_{n\to\infty} \dfrac{ 1 }{ n }\sum_{n=1}^\infty X_n = 0. 
\end{align*}
which implies
\begin{align*}
    \bigcap_{n=N}^\infty \left\{ X_n = 0 \right\} \subset \left\{ \lim_{n\to\infty} \dfrac{ 1 }{ n }\sum_{i=1}^n X_i = 0 \right\}. 
\end{align*}

On the other hand, by the Borel-Cantelli lemma we have
\begin{align*}
    \mathbb{P}\left( X_n = n^2 \right) = \dfrac{ 1 }{ n^2 }  \Rightarrow &\sum_{n=1}^\infty \mathbb{P}\left( X_n = n^2 \right) = \sum_{n=1}^\infty \dfrac{ 1 }{ n^2 } <\infty \\
     \Rightarrow &\mathbb{P}\left( X_n = n^2 \text{ i.o.} \right) = 0\\
        \Rightarrow &\mathbb{P}\left( \bigcap_{N=1}^\infty \bigcup_{n=N}^\infty \left\{ X_n = n^2 \right\} \right) = 0\\
        \Rightarrow &\mathbb{P}\left( \bigcup_{N=1}^\infty \bigcap_{n=N}^\infty \left\{ X_n = 0\right\} \right) = 1\\
\end{align*}
which implies
\begin{align*}
    \mathbb{P}\left( \lim_{n\to\infty} \dfrac{ 1 }{ n }\sum_{n=1}^\infty X_n =0 \right)  \geq \mathbb{P}\left( \bigcap_{n=N}^\infty \left\{ X_n = 0\right\} \right),\quad \forall N\geq 1.
\end{align*}
then we have
\begin{align*}
    \mathbb{P}\left( \lim_{n\to\infty} \dfrac{ 1 }{ n }\sum_{n=1}^\infty X_n =0 \right) \geq 1 \Rightarrow  \dfrac{ 1 }{ n }\sum_{n=1}^\infty X_n \xrightarrow[]{\mathrm{a.s.}} 0.
\end{align*}

\section{SLLN assuming finite fourth moment}
\subsection{}

By Chebyshev's inequality we have
\begin{align*}
    \mathbb{P}\left( \left\vert \dfrac{ 1 }{ n } \sum_{i=1}^n (X_i-m) \right\vert > \dfrac{ 1 }{ r }   \right) \leq & \dfrac{ \mathbb{E}\left[ \left( \sum_{i=1}^n (X_i-m) \right)^4 \right] }{ n^4/r^4 }\\  
\end{align*}

So we need to consider the fourth moment of $ \sum_{i=1}^n (X_i-m) $, as follows: (denote $ Y_i=X_i-m $ the centered random variable) since $ \mathbb{E}Y_i=0 $ we would only have the terms of $ \mathbb{E}Y^4 $ and $ (\mathbb{E}Y^2)^2 $ in the expansion of $ \mathbb{E}(\sum_{i=1}^n Y_i)^4 $, thus we have
\begin{align*}
    \mathbb{E}(\sum_{i=1}^n (X_i-m))^4 =& \mathbb{E}(\sum_{i=1}^n Y_i)^4 = n\mathbb{E}Y^4 + \binom{n}{2}(\mathbb{E}Y^2)^2 := Dn + Cn^2,\quad C,D\in \mathbb{R}^+.
\end{align*}
thus we have 
\begin{align*}
    \mathbb{P}\left( \left\vert \dfrac{ 1 }{ n } \sum_{i=1}^n (X_i-m) \right\vert > \dfrac{ 1 }{ r }   \right) \leq &\dfrac{ \mathbb{E}\left[ \left( \sum_{i=1}^n (X_i-m) \right)^4 \right] }{ n^4/r^4 }= \dfrac{ Dn + Cn^2 }{ n^4/r^4 }\leq \dfrac{ \tilde{C}r^4 }{ n^2 } 
\end{align*}
where $ \tilde{C} $ is some universal constant.

\subsection{}

Note that for any given $ r\in\mathbb{N}^+ $ we have
\begin{align*}
    \sum_{n=1}^\infty  \mathbb{P}\left( \left\vert \dfrac{ 1 }{ n } \sum_{i=1}^n (X_i-m) \right\vert > \dfrac{ 1 }{ r }   \right) \leq & \sum_{n=1}^\infty \dfrac{ \tilde{C}r^4 }{ n^2 } <\infty.
\end{align*}
thus by Borel-Cantelli lemma we have
\begin{align*}
    \mathbb{P}\left( \limsup_{n\to\infty} \left\vert \dfrac{ 1 }{ n } \sum_{i=1}^n (X_i-m) \right\vert > \dfrac{ 1 }{ r } \right) =0  \Rightarrow   \mathbb{P}\left( \limsup_{n\to\infty} \left\vert \dfrac{ 1 }{ n } \sum_{i=1}^n (X_i-m) \right\vert =0 \right) =1  \Rightarrow \dfrac{ 1 }{ n } \sum_{i=1}^n (X_i-m) \xrightarrow[]{\mathrm{a.s.}} 0.
\end{align*}





































    



    










\end{document}